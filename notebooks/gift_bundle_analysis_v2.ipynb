{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "166ffd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271cee37",
   "metadata": {},
   "source": [
    "## Load and aggressively filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d4ce46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 1,067,371 rows\n",
      "After cleaning + UK filter: 958,501 rows\n",
      "After cleaning + UK filter: 958,501 rows\n",
      "Unique products: 5,237\n",
      "Unique transactions: 36,422\n",
      "Unique products: 5,237\n",
      "Unique transactions: 36,422\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/online_retail_II.csv', encoding='ISO-8859-1')\n",
    "print(f\"Original: {len(df):,} rows\")\n",
    "\n",
    "df_clean = df[\n",
    "    (~df['Invoice'].astype(str).str.startswith('C')) &\n",
    "    (df['Quantity'] > 0) &\n",
    "    (df['Price'] > 0) &\n",
    "    (df['Description'].notna()) &\n",
    "    (df['Country'] == 'United Kingdom')\n",
    "].copy()\n",
    "\n",
    "print(f\"After cleaning + UK filter: {len(df_clean):,} rows\")\n",
    "\n",
    "df_clean['Description'] = df_clean['Description'].str.strip().str.upper()\n",
    "df_clean['Description'] = df_clean['Description'].str.replace('[^A-Z0-9 ]', '', regex=True)\n",
    "df_clean['Description'] = df_clean['Description'].str.replace('\\s+', ' ', regex=True)\n",
    "\n",
    "df_clean = df_clean[~df_clean['Description'].str.contains('POSTAGE|DOTCOM|BANK CHARGES|SAMPLES|ADJUST|DISCOUNT', na=False)]\n",
    "\n",
    "print(f\"Unique products: {df_clean['Description'].nunique():,}\")\n",
    "print(f\"Unique transactions: {df_clean['Invoice'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf4eb9",
   "metadata": {},
   "source": [
    "## Selecting and viewing top products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57814cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 200 products:\n",
      "Description\n",
      "WHITE HANGING HEART TLIGHT HOLDER      5569\n",
      "REGENCY CAKESTAND 3 TIER               3574\n",
      "JUMBO BAG RED RETROSPOT                3163\n",
      "ASSORTED COLOUR BIRD ORNAMENT          2778\n",
      "PARTY BUNTING                          2598\n",
      "                                       ... \n",
      "WOODEN HEART CHRISTMAS SCANDINAVIAN     829\n",
      "FELTCRAFT CUSHION RABBIT                829\n",
      "METAL SIGN TAKE IT OR LEAVE IT          828\n",
      "TRADITIONAL WOODEN SKIPPING ROPE        827\n",
      "JUMBO BAG VINTAGE LEAF                  825\n",
      "Name: count, Length: 200, dtype: int64\n",
      "\n",
      "Top product appears in: 5,569 transactions\n",
      "#50 product appears in: 1,430 transactions\n",
      "#100 product appears in: 1,114 transactions\n"
     ]
    }
   ],
   "source": [
    "top_products = df_clean['Description'].value_counts().head(200)\n",
    "print(\"Top 200 products:\")\n",
    "print(top_products)\n",
    "\n",
    "print(f\"\\nTop product appears in: {top_products.iloc[0]:,} transactions\")\n",
    "print(f\"#50 product appears in: {top_products.iloc[49]:,} transactions\")\n",
    "print(f\"#100 product appears in: {top_products.iloc[99]:,} transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "724bbd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered to 200 products:\n",
      "Transactions: 255,814\n",
      "Unique invoices: 30,763\n",
      "\n",
      "Selected products:\n",
      " 1. WHITE HANGING HEART TLIGHT HOLDER\n",
      " 2. REGENCY CAKESTAND 3 TIER\n",
      " 3. JUMBO BAG RED RETROSPOT\n",
      " 4. ASSORTED COLOUR BIRD ORNAMENT\n",
      " 5. PARTY BUNTING\n",
      " 6. LUNCH BAG BLACK SKULL\n",
      " 7. LUNCH BAG SUKI DESIGN\n",
      " 8. JUMBO STORAGE BAG SUKI\n",
      " 9. STRAWBERRY CERAMIC TRINKET BOX\n",
      "10. HEART OF WICKER SMALL\n",
      "11. JUMBO SHOPPER VINTAGE RED PAISLEY\n",
      "12. REX CASHCARRY JUMBO SHOPPER\n",
      "13. PAPER CHAIN KIT 50S CHRISTMAS\n",
      "14. HOME BUILDING BLOCK WORD\n",
      "15. WOODEN FRAME ANTIQUE WHITE\n",
      "16. NATURAL SLATE HEART CHALKBOARD\n",
      "17. HEART OF WICKER LARGE\n",
      "18. 60 TEATIME FAIRY CAKE CASES\n",
      "19. WOODEN PICTURE FRAME WHITE FINISH\n",
      "20. LUNCH BAG SPACEBOY DESIGN\n",
      "\n",
      "Transactions: 255,814\n",
      "Unique invoices: 30,763\n",
      "\n",
      "Selected products:\n",
      " 1. WHITE HANGING HEART TLIGHT HOLDER\n",
      " 2. REGENCY CAKESTAND 3 TIER\n",
      " 3. JUMBO BAG RED RETROSPOT\n",
      " 4. ASSORTED COLOUR BIRD ORNAMENT\n",
      " 5. PARTY BUNTING\n",
      " 6. LUNCH BAG BLACK SKULL\n",
      " 7. LUNCH BAG SUKI DESIGN\n",
      " 8. JUMBO STORAGE BAG SUKI\n",
      " 9. STRAWBERRY CERAMIC TRINKET BOX\n",
      "10. HEART OF WICKER SMALL\n",
      "11. JUMBO SHOPPER VINTAGE RED PAISLEY\n",
      "12. REX CASHCARRY JUMBO SHOPPER\n",
      "13. PAPER CHAIN KIT 50S CHRISTMAS\n",
      "14. HOME BUILDING BLOCK WORD\n",
      "15. WOODEN FRAME ANTIQUE WHITE\n",
      "16. NATURAL SLATE HEART CHALKBOARD\n",
      "17. HEART OF WICKER LARGE\n",
      "18. 60 TEATIME FAIRY CAKE CASES\n",
      "19. WOODEN PICTURE FRAME WHITE FINISH\n",
      "20. LUNCH BAG SPACEBOY DESIGN\n"
     ]
    }
   ],
   "source": [
    "TOP_N = 200\n",
    "\n",
    "selected_products = df_clean['Description'].value_counts().head(TOP_N).index\n",
    "df_filtered = df_clean[df_clean['Description'].isin(selected_products)].copy()\n",
    "\n",
    "print(f\"\\nFiltered to {TOP_N} products:\")\n",
    "print(f\"Transactions: {len(df_filtered):,}\")\n",
    "print(f\"Unique invoices: {df_filtered['Invoice'].nunique():,}\")\n",
    "print(f\"\\nSelected products:\")\n",
    "for i, prod in enumerate(selected_products[:20], 1):\n",
    "    print(f\"{i:2}. {prod}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783e5696",
   "metadata": {},
   "source": [
    "## Transaction basket attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e1b380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basket shape: (30763, 200)\n",
      "Sparsity: 96.1%\n",
      "\n",
      "Basket sizes (from our 200 products):\n",
      "count    30763.000000\n",
      "mean         7.897182\n",
      "std          9.669511\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          5.000000\n",
      "75%         10.000000\n",
      "max        148.000000\n",
      "dtype: float64\n",
      "\n",
      "After removing single-item baskets: 26,360 transactions\n"
     ]
    }
   ],
   "source": [
    "basket = df_filtered.groupby(['Invoice', 'Description'])['Quantity'].sum().unstack().reset_index().fillna(0).set_index('Invoice')\n",
    "\n",
    "basket_encoded = (basket > 0).astype(int)\n",
    "\n",
    "print(f\"Basket shape: {basket_encoded.shape}\")\n",
    "print(f\"Sparsity: {(basket_encoded == 0).sum().sum() / (basket_encoded.shape[0] * basket_encoded.shape[1]) * 100:.1f}%\")\n",
    "\n",
    "basket_sizes = basket_encoded.sum(axis=1)\n",
    "print(f\"\\nBasket sizes (from our {TOP_N} products):\")\n",
    "print(basket_sizes.describe())\n",
    "\n",
    "basket_encoded = basket_encoded[basket_sizes >= 2]\n",
    "print(f\"\\nAfter removing single-item baskets: {basket_encoded.shape[0]:,} transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723d44cf",
   "metadata": {},
   "source": [
    "## FP-Growth run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74aecc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOST TIME CONSUMING AREA. Initial runs took 20+ minutes. Currently optimized to around 8 minutes. Atleast 15 hours spent here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0bd8b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running FP-Growth with min_support=0.005 (0.5%)...\n",
      "✓ Found 9,734 frequent itemsets\n",
      "\n",
      "Itemset size distribution:\n",
      "length\n",
      "1     200\n",
      "2    5609\n",
      "3    3151\n",
      "4     673\n",
      "5      98\n",
      "6       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "3+ item sets: 3925\n",
      "\n",
      "Top 10 largest itemsets by support:\n",
      "\n",
      "Size 3, Support: 0.0251\n",
      "  - PINK REGENCY TEACUP AND SAUCER\n",
      "  - GREEN REGENCY TEACUP AND SAUCER\n",
      "  - ROSES REGENCY TEACUP AND SAUCER\n",
      "\n",
      "Size 3, Support: 0.0204\n",
      "  - JUMBO SHOPPER VINTAGE RED PAISLEY\n",
      "  - JUMBO BAG RED RETROSPOT\n",
      "  - JUMBO STORAGE BAG SUKI\n",
      "\n",
      "Size 3, Support: 0.0193\n",
      "  - ROSES REGENCY TEACUP AND SAUCER\n",
      "  - REGENCY CAKESTAND 3 TIER\n",
      "  - GREEN REGENCY TEACUP AND SAUCER\n",
      "\n",
      "Size 3, Support: 0.0192\n",
      "  - LUNCH BAG SUKI DESIGN\n",
      "  - LUNCH BAG SPACEBOY DESIGN\n",
      "  - LUNCH BAG BLACK SKULL\n",
      "\n",
      "Size 3, Support: 0.0191\n",
      "  - WHITE HANGING HEART TLIGHT HOLDER\n",
      "  - WOODEN PICTURE FRAME WHITE FINISH\n",
      "  - WOODEN FRAME ANTIQUE WHITE\n",
      "\n",
      "Size 3, Support: 0.0187\n",
      "  - LUNCH BAG SUKI DESIGN\n",
      "  - LUNCH BAG CARS BLUE\n",
      "  - LUNCH BAG BLACK SKULL\n",
      "\n",
      "Size 3, Support: 0.0186\n",
      "  - LUNCH BAG SUKI DESIGN\n",
      "  - LUNCH BAG SPACEBOY DESIGN\n",
      "  - LUNCH BAG CARS BLUE\n",
      "\n",
      "Size 3, Support: 0.0182\n",
      "  - CHARLOTTE BAG SUKI DESIGN\n",
      "  - WOODLAND CHARLOTTE BAG\n",
      "  - STRAWBERRY CHARLOTTE BAG\n",
      "\n",
      "Size 3, Support: 0.0181\n",
      "  - JUMBO BAG BAROQUE BLACK WHITE\n",
      "  - JUMBO BAG RED RETROSPOT\n",
      "  - JUMBO STORAGE BAG SUKI\n",
      "\n",
      "Size 3, Support: 0.0176\n",
      "  - JUMBO BAG RED RETROSPOT\n",
      "  - JUMBO STORAGE BAG SUKI\n",
      "  - JUMBO BAG PINK POLKADOT\n",
      "✓ Found 9,734 frequent itemsets\n",
      "\n",
      "Itemset size distribution:\n",
      "length\n",
      "1     200\n",
      "2    5609\n",
      "3    3151\n",
      "4     673\n",
      "5      98\n",
      "6       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "3+ item sets: 3925\n",
      "\n",
      "Top 10 largest itemsets by support:\n",
      "\n",
      "Size 3, Support: 0.0251\n",
      "  - PINK REGENCY TEACUP AND SAUCER\n",
      "  - GREEN REGENCY TEACUP AND SAUCER\n",
      "  - ROSES REGENCY TEACUP AND SAUCER\n",
      "\n",
      "Size 3, Support: 0.0204\n",
      "  - JUMBO SHOPPER VINTAGE RED PAISLEY\n",
      "  - JUMBO BAG RED RETROSPOT\n",
      "  - JUMBO STORAGE BAG SUKI\n",
      "\n",
      "Size 3, Support: 0.0193\n",
      "  - ROSES REGENCY TEACUP AND SAUCER\n",
      "  - REGENCY CAKESTAND 3 TIER\n",
      "  - GREEN REGENCY TEACUP AND SAUCER\n",
      "\n",
      "Size 3, Support: 0.0192\n",
      "  - LUNCH BAG SUKI DESIGN\n",
      "  - LUNCH BAG SPACEBOY DESIGN\n",
      "  - LUNCH BAG BLACK SKULL\n",
      "\n",
      "Size 3, Support: 0.0191\n",
      "  - WHITE HANGING HEART TLIGHT HOLDER\n",
      "  - WOODEN PICTURE FRAME WHITE FINISH\n",
      "  - WOODEN FRAME ANTIQUE WHITE\n",
      "\n",
      "Size 3, Support: 0.0187\n",
      "  - LUNCH BAG SUKI DESIGN\n",
      "  - LUNCH BAG CARS BLUE\n",
      "  - LUNCH BAG BLACK SKULL\n",
      "\n",
      "Size 3, Support: 0.0186\n",
      "  - LUNCH BAG SUKI DESIGN\n",
      "  - LUNCH BAG SPACEBOY DESIGN\n",
      "  - LUNCH BAG CARS BLUE\n",
      "\n",
      "Size 3, Support: 0.0182\n",
      "  - CHARLOTTE BAG SUKI DESIGN\n",
      "  - WOODLAND CHARLOTTE BAG\n",
      "  - STRAWBERRY CHARLOTTE BAG\n",
      "\n",
      "Size 3, Support: 0.0181\n",
      "  - JUMBO BAG BAROQUE BLACK WHITE\n",
      "  - JUMBO BAG RED RETROSPOT\n",
      "  - JUMBO STORAGE BAG SUKI\n",
      "\n",
      "Size 3, Support: 0.0176\n",
      "  - JUMBO BAG RED RETROSPOT\n",
      "  - JUMBO STORAGE BAG SUKI\n",
      "  - JUMBO BAG PINK POLKADOT\n"
     ]
    }
   ],
   "source": [
    "min_support = 0.005\n",
    "\n",
    "print(f\"Running FP-Growth with min_support={min_support} ({min_support*100}%)...\")\n",
    "frequent_itemsets = fpgrowth(basket_encoded, min_support=min_support, use_colnames=True)\n",
    "\n",
    "print(f\"✓ Found {len(frequent_itemsets):,} frequent itemsets\")\n",
    "\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(len)\n",
    "print(f\"\\nItemset size distribution:\")\n",
    "print(frequent_itemsets['length'].value_counts().sort_index())\n",
    "\n",
    "large_sets = frequent_itemsets[frequent_itemsets['length'] >= 3].sort_values('support', ascending=False)\n",
    "print(f\"\\n3+ item sets: {len(large_sets)}\")\n",
    "if len(large_sets) > 0:\n",
    "    print(\"\\nTop 10 largest itemsets by support:\")\n",
    "    for idx, row in large_sets.head(10).iterrows():\n",
    "        items = list(row['itemsets'])\n",
    "        print(f\"\\nSize {len(items)}, Support: {row['support']:.4f}\")\n",
    "        for item in items:\n",
    "            print(f\"  - {item[:60]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4540a155",
   "metadata": {},
   "source": [
    "## Generate association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0011ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating rules with min_confidence=0.3...\n",
      "Generated 14,768 rules\n",
      "\n",
      "Rule statistics:\n",
      "            support    confidence          lift\n",
      "count  14768.000000  14768.000000  14768.000000\n",
      "mean       0.006807      0.519523     12.969205\n",
      "std        0.003112      0.151680      9.342416\n",
      "min        0.005008      0.300000      1.562112\n",
      "25%        0.005311      0.392464      6.795523\n",
      "50%        0.005842      0.494683      9.887961\n",
      "75%        0.006904      0.625000     15.833775\n",
      "max        0.044575      0.978571     61.268044\n",
      "\n",
      "Rules by total items:\n",
      "total_items\n",
      "2     546\n",
      "3    7385\n",
      "4    4879\n",
      "5    1816\n",
      "6     142\n",
      "Name: count, dtype: int64\n",
      "Generated 14,768 rules\n",
      "\n",
      "Rule statistics:\n",
      "            support    confidence          lift\n",
      "count  14768.000000  14768.000000  14768.000000\n",
      "mean       0.006807      0.519523     12.969205\n",
      "std        0.003112      0.151680      9.342416\n",
      "min        0.005008      0.300000      1.562112\n",
      "25%        0.005311      0.392464      6.795523\n",
      "50%        0.005842      0.494683      9.887961\n",
      "75%        0.006904      0.625000     15.833775\n",
      "max        0.044575      0.978571     61.268044\n",
      "\n",
      "Rules by total items:\n",
      "total_items\n",
      "2     546\n",
      "3    7385\n",
      "4    4879\n",
      "5    1816\n",
      "6     142\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "min_confidence = 0.3\n",
    "\n",
    "print(f\"Generating rules with min_confidence={min_confidence}...\")\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "print(f\"Generated {len(rules):,} rules\")\n",
    "\n",
    "if len(rules) > 0:\n",
    "    rules['ant_len'] = rules['antecedents'].apply(len)\n",
    "    rules['cons_len'] = rules['consequents'].apply(len)\n",
    "    rules['total_items'] = rules['ant_len'] + rules['cons_len']\n",
    "    \n",
    "    print(f\"\\nRule statistics:\")\n",
    "    print(rules[['support', 'confidence', 'lift']].describe())\n",
    "    \n",
    "    print(f\"\\nRules by total items:\")\n",
    "    print(rules['total_items'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c217ba6",
   "metadata": {},
   "source": [
    "## Try finding interesting bundles (might use this style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c913b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10594 interesting bundles (3+ items, lift>2, conf>0.4)\n",
      "TOP 20 GIFT BUNDLES\n",
      "Bundle #1 (Lift: 61.27, Conf: 0.43, Supp: 0.0050)\n",
      "If customer buys:\n",
      "  ✓ PACK OF 72 RETROSPOT CAKE CASES\n",
      "  ✓ WOODLAND CHARLOTTE BAG\n",
      "They also likely buy:\n",
      "  → CHARLOTTE BAG PINK POLKADOT\n",
      "  → REGENCY CAKESTAND 3 TIER\n",
      "  → CHARLOTTE BAG SUKI DESIGN\n",
      "\n",
      "Bundle #2 (Lift: 61.27, Conf: 0.71, Supp: 0.0050)\n",
      "If customer buys:\n",
      "  ✓ CHARLOTTE BAG PINK POLKADOT\n",
      "  ✓ REGENCY CAKESTAND 3 TIER\n",
      "  ✓ CHARLOTTE BAG SUKI DESIGN\n",
      "They also likely buy:\n",
      "  → PACK OF 72 RETROSPOT CAKE CASES\n",
      "  → WOODLAND CHARLOTTE BAG\n",
      "\n",
      "Bundle #3 (Lift: 60.48, Conf: 0.47, Supp: 0.0050)\n",
      "If customer buys:\n",
      "  ✓ PACK OF 72 RETROSPOT CAKE CASES\n",
      "  ✓ STRAWBERRY CHARLOTTE BAG\n",
      "They also likely buy:\n",
      "  → RED RETROSPOT CHARLOTTE BAG\n",
      "  → REGENCY CAKESTAND 3 TIER\n",
      "  → CHARLOTTE BAG SUKI DESIGN\n",
      "\n",
      "Bundle #4 (Lift: 60.48, Conf: 0.65, Supp: 0.0050)\n",
      "If customer buys:\n",
      "  ✓ RED RETROSPOT CHARLOTTE BAG\n",
      "  ✓ REGENCY CAKESTAND 3 TIER\n",
      "  ✓ CHARLOTTE BAG SUKI DESIGN\n",
      "They also likely buy:\n",
      "  → PACK OF 72 RETROSPOT CAKE CASES\n",
      "  → STRAWBERRY CHARLOTTE BAG\n",
      "\n",
      "Bundle #5 (Lift: 60.32, Conf: 0.44, Supp: 0.0051)\n",
      "If customer buys:\n",
      "  ✓ CHARLOTTE BAG PINK POLKADOT\n",
      "  ✓ PACK OF 72 RETROSPOT CAKE CASES\n",
      "They also likely buy:\n",
      "  → RED RETROSPOT CHARLOTTE BAG\n",
      "  → REGENCY CAKESTAND 3 TIER\n",
      "  → WOODLAND CHARLOTTE BAG\n",
      "\n",
      "Bundle #6 (Lift: 60.32, Conf: 0.70, Supp: 0.0051)\n",
      "If customer buys:\n",
      "  ✓ RED RETROSPOT CHARLOTTE BAG\n",
      "  ✓ REGENCY CAKESTAND 3 TIER\n",
      "  ✓ WOODLAND CHARLOTTE BAG\n",
      "They also likely buy:\n",
      "  → CHARLOTTE BAG PINK POLKADOT\n",
      "  → PACK OF 72 RETROSPOT CAKE CASES\n",
      "\n",
      "Bundle #7 (Lift: 59.65, Conf: 0.53, Supp: 0.0051)\n",
      "If customer buys:\n",
      "  ✓ CHARLOTTE BAG PINK POLKADOT\n",
      "  ✓ REGENCY CAKESTAND 3 TIER\n",
      "They also likely buy:\n",
      "  → PACK OF 72 RETROSPOT CAKE CASES\n",
      "  → WOODLAND CHARLOTTE BAG\n",
      "  → RED RETROSPOT CHARLOTTE BAG\n",
      "\n",
      "Bundle #8 (Lift: 59.65, Conf: 0.57, Supp: 0.0051)\n",
      "If customer buys:\n",
      "  ✓ PACK OF 72 RETROSPOT CAKE CASES\n",
      "  ✓ WOODLAND CHARLOTTE BAG\n",
      "  ✓ RED RETROSPOT CHARLOTTE BAG\n",
      "They also likely buy:\n",
      "  → CHARLOTTE BAG PINK POLKADOT\n",
      "  → REGENCY CAKESTAND 3 TIER\n",
      "\n",
      "Bundle #9 (Lift: 59.31, Conf: 0.46, Supp: 0.0053)\n",
      "If customer buys:\n",
      "  ✓ CHARLOTTE BAG PINK POLKADOT\n",
      "  ✓ PACK OF 72 RETROSPOT CAKE CASES\n",
      "They also likely buy:\n",
      "  → RED RETROSPOT CHARLOTTE BAG\n",
      "  → REGENCY CAKESTAND 3 TIER\n",
      "  → CHARLOTTE BAG SUKI DESIGN\n",
      "\n",
      "Bundle #10 (Lift: 59.31, Conf: 0.69, Supp: 0.0053)\n",
      "If customer buys:\n",
      "  ✓ RED RETROSPOT CHARLOTTE BAG\n",
      "  ✓ REGENCY CAKESTAND 3 TIER\n",
      "  ✓ CHARLOTTE BAG SUKI DESIGN\n",
      "They also likely buy:\n",
      "  → CHARLOTTE BAG PINK POLKADOT\n",
      "  → PACK OF 72 RETROSPOT CAKE CASES\n",
      "\n",
      "Bundle #11 (Lift: 58.70, Conf: 0.56, Supp: 0.0050)\n",
      "If customer buys:\n",
      "  ✓ PACK OF 72 RETROSPOT CAKE CASES\n",
      "  ✓ CHARLOTTE BAG SUKI DESIGN\n",
      "  ✓ WOODLAND CHARLOTTE BAG\n",
      "They also likely buy:\n",
      "  → CHARLOTTE BAG PINK POLKADOT\n",
      "  → REGENCY CAKESTAND 3 TIER\n",
      "\n",
      "Bundle #12 (Lift: 58.70, Conf: 0.53, Supp: 0.0050)\n",
      "If customer buys:\n",
      "  ✓ CHARLOTTE BAG PINK POLKADOT\n",
      "  ✓ REGENCY CAKESTAND 3 TIER\n",
      "They also likely buy:\n",
      "  → PACK OF 72 RETROSPOT CAKE CASES\n",
      "  → CHARLOTTE BAG SUKI DESIGN\n",
      "  → WOODLAND CHARLOTTE BAG\n",
      "\n",
      "Bundle #13 (Lift: 57.85, Conf: 0.67, Supp: 0.0052)\n",
      "If customer buys:\n",
      "  ✓ RED RETROSPOT CHARLOTTE BAG\n",
      "  ✓ REGENCY CAKESTAND 3 TIER\n",
      "  ✓ CHARLOTTE BAG SUKI DESIGN\n",
      "They also likely buy:\n",
      "  → PACK OF 72 RETROSPOT CAKE CASES\n",
      "  → WOODLAND CHARLOTTE BAG\n",
      "\n",
      "Bundle #14 (Lift: 57.85, Conf: 0.45, Supp: 0.0052)\n",
      "If customer buys:\n",
      "  ✓ PACK OF 72 RETROSPOT CAKE CASES\n",
      "  ✓ WOODLAND CHARLOTTE BAG\n",
      "They also likely buy:\n",
      "  → RED RETROSPOT CHARLOTTE BAG\n",
      "  → REGENCY CAKESTAND 3 TIER\n",
      "  → CHARLOTTE BAG SUKI DESIGN\n",
      "\n",
      "Bundle #15 (Lift: 57.67, Conf: 0.73, Supp: 0.0050)\n",
      "If customer buys:\n",
      "  ✓ CHARLOTTE BAG PINK POLKADOT\n",
      "  ✓ REGENCY CAKESTAND 3 TIER\n",
      "  ✓ WOODLAND CHARLOTTE BAG\n",
      "They also likely buy:\n",
      "  → PACK OF 72 RETROSPOT CAKE CASES\n",
      "  → CHARLOTTE BAG SUKI DESIGN\n",
      "\n",
      "Bundle #16 (Lift: 57.02, Conf: 0.45, Supp: 0.0050)\n",
      "If customer buys:\n",
      "  ✓ RED RETROSPOT CHARLOTTE BAG\n",
      "  ✓ REGENCY CAKESTAND 3 TIER\n",
      "They also likely buy:\n",
      "  → PACK OF 72 RETROSPOT CAKE CASES\n",
      "  → CHARLOTTE BAG SUKI DESIGN\n",
      "  → STRAWBERRY CHARLOTTE BAG\n",
      "\n",
      "Bundle #17 (Lift: 57.02, Conf: 0.63, Supp: 0.0050)\n",
      "If customer buys:\n",
      "  ✓ PACK OF 72 RETROSPOT CAKE CASES\n",
      "  ✓ CHARLOTTE BAG SUKI DESIGN\n",
      "  ✓ STRAWBERRY CHARLOTTE BAG\n",
      "They also likely buy:\n",
      "  → RED RETROSPOT CHARLOTTE BAG\n",
      "  → REGENCY CAKESTAND 3 TIER\n",
      "\n",
      "Bundle #18 (Lift: 56.61, Conf: 0.72, Supp: 0.0052)\n",
      "If customer buys:\n",
      "  ✓ CHARLOTTE BAG PINK POLKADOT\n",
      "  ✓ PACK OF 72 SKULL CAKE CASES\n",
      "They also likely buy:\n",
      "  → PACK OF 72 RETROSPOT CAKE CASES\n",
      "  → CHARLOTTE BAG SUKI DESIGN\n",
      "\n",
      "Bundle #19 (Lift: 56.61, Conf: 0.41, Supp: 0.0052)\n",
      "If customer buys:\n",
      "  ✓ PACK OF 72 RETROSPOT CAKE CASES\n",
      "  ✓ CHARLOTTE BAG SUKI DESIGN\n",
      "They also likely buy:\n",
      "  → CHARLOTTE BAG PINK POLKADOT\n",
      "  → PACK OF 72 SKULL CAKE CASES\n",
      "\n",
      "Bundle #20 (Lift: 56.54, Conf: 0.56, Supp: 0.0053)\n",
      "If customer buys:\n",
      "  ✓ CHARLOTTE BAG PINK POLKADOT\n",
      "  ✓ REGENCY CAKESTAND 3 TIER\n",
      "They also likely buy:\n",
      "  → PACK OF 72 RETROSPOT CAKE CASES\n",
      "  → CHARLOTTE BAG SUKI DESIGN\n",
      "  → RED RETROSPOT CHARLOTTE BAG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interesting_rules = rules[\n",
    "    (rules['total_items'] >= 3) &\n",
    "    (rules['lift'] > 2) &\n",
    "    (rules['confidence'] > 0.4)\n",
    "].copy()\n",
    "\n",
    "interesting_rules = interesting_rules.sort_values('lift', ascending=False)\n",
    "\n",
    "print(f\"Found {len(interesting_rules)} interesting bundles (3+ items, lift>2, conf>0.4)\")\n",
    "\n",
    "if len(interesting_rules) > 0:\n",
    "    print(\"TOP 20 GIFT BUNDLES\")\n",
    "    \n",
    "    for idx, (i, row) in enumerate(interesting_rules.head(20).iterrows(), 1):\n",
    "        ant_items = list(row['antecedents'])\n",
    "        cons_items = list(row['consequents'])\n",
    "        \n",
    "        print(f\"Bundle #{idx} (Lift: {row['lift']:.2f}, Conf: {row['confidence']:.2f}, Supp: {row['support']:.4f})\")\n",
    "        print(\"If customer buys:\")\n",
    "        for item in ant_items:\n",
    "            print(f\"  ✓ {item[:70]}\")\n",
    "        print(\"They also likely buy:\")\n",
    "        for item in cons_items:\n",
    "            print(f\"  → {item[:70]}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"\\nNo rules found with these criteria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4040ed",
   "metadata": {},
   "source": [
    "## 2item pair analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e3e678b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 545 strong 2-item pairs (lift>1.5, conf>0.3)\n",
      "TOP 2-ITEM PAIRS (High Lift Only)\n"
     ]
    }
   ],
   "source": [
    "pair_rules = rules[\n",
    "    (rules['ant_len'] == 1) & \n",
    "    (rules['cons_len'] == 1) &\n",
    "    (rules['lift'] > 1.5) &\n",
    "    (rules['confidence'] > 0.3)\n",
    "].copy()\n",
    "\n",
    "pair_rules = pair_rules.sort_values('lift', ascending=False)\n",
    "\n",
    "print(f\"\\nFound {len(pair_rules)} strong 2-item pairs (lift>1.5, conf>0.3)\")\n",
    "\n",
    "if len(pair_rules) > 0:\n",
    "    print(\"TOP 2-ITEM PAIRS (High Lift Only)\")\n",
    "    \n",
    "    for idx, (i, row) in enumerate(pair_rules.head(30).iterrows(), 1):\n",
    "        item1 = list(row['antecedents'])[0]\n",
    "        item2 = list(row['consequents'])[0]\n",
    "        \n",
    "        words1 = set(item1.split())\n",
    "        words2 = set(item2.split())\n",
    "        overlap = len(words1 & words2)\n",
    "        \n",
    "        if overlap <= 1:\n",
    "            print(f\"Pair #{idx}: Lift={row['lift']:.2f}, Conf={row['confidence']:.2f}\")\n",
    "            print(f\"  {item1[:65]}\")\n",
    "            print(f\"  + {item2[:65]}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2544e26",
   "metadata": {},
   "source": [
    "## Manual bundle categorization (potentially)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4733a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_bundles = {\n",
    "    'Classic Combos': [\n",
    "    ],\n",
    "    'Seasonal Sets': [\n",
    "    ],\n",
    "    'Niche Discoveries': [\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d475eee9",
   "metadata": {},
   "source": [
    "## Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e57dff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 545 pairs\n",
      "Lift range: 1.56 - 18.40\n"
     ]
    }
   ],
   "source": [
    "if len(pair_rules) > 0:\n",
    "    export_pairs = pair_rules.copy()\n",
    "    export_pairs['antecedents'] = export_pairs['antecedents'].apply(lambda x: list(x)[0])\n",
    "    export_pairs['consequents'] = export_pairs['consequents'].apply(lambda x: list(x)[0])\n",
    "    \n",
    "    export_pairs[['antecedents', 'consequents', 'support', 'confidence', 'lift']].to_csv(\n",
    "        '../outputs/results/strong_pairs.csv', index=False\n",
    "    )\n",
    "    print(f\"Exported {len(export_pairs)} pairs\")\n",
    "    print(f\"Lift range: {export_pairs['lift'].min():.2f} - {export_pairs['lift'].max():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
